Extremely slow but mostly functional subset of pytorch, with an autodiff engine and small nn library. 
Inspired by Karpathy's micrograd but supporting tensor-valued nodes and some more operations like broadcasting, matrix multiplication and convolutions. See demos/mnist.ipynb for example usage

## Links
- [Karpathys video](https://www.youtube.com/watch?v=VMj-3S1tku0&t=83s) on autograd
- [Course](https://dlvu.github.io/backpropagation/) on autograd
- [Colab](https://colab.research.google.com/drive/1VpeE6UvEPRz9HmsHh1KS0XxXjYu533EC#scrollTo=2Lf8JaEK4MHJ)
  example implementation of pytorch autograd
- [Articles](https://d2l.ai/chapter_optimization/sgd.html) on optimization algorithms, other good articles on same site (d2l.ai)